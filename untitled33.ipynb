{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO3zqWfqNantPtFPqKarc3u",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/UrvashiiThakur/practiceGit/blob/main/untitled33.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7mQzhuY8iIjU"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q1. What is anomaly detection and what is its purpose?\n",
        "\n",
        "Anomaly detection is the process of identifying unusual patterns that do not conform to expected behavior. It is used in various fields such as fraud detection, network security, fault detection in systems, and more. The primary purpose is to detect deviations from the norm that could indicate critical incidents or issues requiring attention.\n",
        "\n",
        "### Q2. What are the key challenges in anomaly detection?\n",
        "\n",
        "1. **Defining Normal Behavior:** Establishing what constitutes normal behavior can be complex, especially in dynamic environments.\n",
        "2. **Imbalanced Data:** Anomalies are often rare compared to normal instances, making the dataset imbalanced.\n",
        "3. **Variability of Anomalies:** Anomalies can vary greatly, making it hard to define a one-size-fits-all model.\n",
        "4. **Noise in Data:** Distinguishing between noise and actual anomalies can be difficult.\n",
        "5. **Real-Time Processing:** Detecting anomalies in real-time requires efficient and scalable algorithms.\n",
        "\n",
        "### Q3. How does unsupervised anomaly detection differ from supervised anomaly detection?\n",
        "\n",
        "- **Supervised Anomaly Detection:** Uses labeled training data to learn the characteristics of normal and anomalous instances. It requires a large dataset with labeled anomalies.\n",
        "- **Unsupervised Anomaly Detection:** Does not rely on labeled data. It assumes that normal instances are much more frequent than anomalies and uses this assumption to identify outliers.\n",
        "\n",
        "### Q4. What are the main categories of anomaly detection algorithms?\n",
        "\n",
        "1. **Statistical Methods:** Assumes data is generated by a statistical process and detects anomalies as data points that do not conform to the statistical properties of the data.\n",
        "2. **Distance-Based Methods:** Measures the distance between data points, identifying those that are distant from the majority as anomalies.\n",
        "3. **Density-Based Methods:** Identifies regions of low density in the data space, assuming anomalies occur in these regions.\n",
        "4. **Clustering-Based Methods:** Uses clustering algorithms to group data and identifies points that do not fit well into any cluster.\n",
        "5. **Machine Learning-Based Methods:** Utilizes models such as neural networks, support vector machines, and isolation forests.\n",
        "\n",
        "### Q5. What are the main assumptions made by distance-based anomaly detection methods?\n",
        "\n",
        "1. **Normal Data Density:** Normal data points are assumed to be densely packed together.\n",
        "2. **Anomalous Data Sparsity:** Anomalies are assumed to lie far from the dense regions of normal data.\n",
        "3. **Distance Measure:** A suitable distance metric (e.g., Euclidean distance) can accurately reflect the dissimilarity between data points.\n",
        "\n",
        "### Q6. How does the LOF algorithm compute anomaly scores?\n",
        "\n",
        "The Local Outlier Factor (LOF) algorithm measures the local density deviation of a data point compared to its neighbors. The LOF score indicates how isolated a point is with respect to the surrounding neighborhood. It is calculated by comparing the density around a point with the density around its neighbors. A higher LOF score indicates a higher likelihood of being an anomaly.\n",
        "\n",
        "### Q7. What are the key parameters of the Isolation Forest algorithm?\n",
        "\n",
        "1. **Number of Trees (n_estimators):** The number of trees to build in the forest.\n",
        "2. **Subsampling Size (max_samples):** The number of samples to draw from the dataset to train each tree.\n",
        "3. **Contamination:** The expected proportion of outliers in the data.\n",
        "4. **Random State:** Seed for the random number generator for reproducibility.\n",
        "\n",
        "### Q8. If a data point has only 2 neighbors of the same class within a radius of 0.5, what is its anomaly score using KNN with K=10?\n",
        "\n",
        "In KNN-based anomaly detection, the anomaly score can be defined as the distance to the Kth nearest neighbor. If K=10 and the data point has only 2 neighbors within the specified radius, it is likely to be considered an anomaly due to its low number of close neighbors compared to the required K neighbors.\n",
        "\n",
        "### Q9. Using the Isolation Forest algorithm with 100 trees and a dataset of 3000 data points, what is the anomaly score for a data point that has an average path length of 5.0 compared to the average path length of the trees?\n",
        "\n",
        "In Isolation Forest, the anomaly score \\(s(x, n)\\) for a data point \\(x\\) can be calculated as follows:\n",
        "\\[ s(x, n) = 2^{-\\frac{E(h(x))}{c(n)}} \\]\n",
        "\n",
        "where:\n",
        "- \\(E(h(x))\\) is the average path length of \\(x\\).\n",
        "- \\(c(n)\\) is the average path length of unsuccessful searches in a binary search tree, approximated as \\(c(n) = 2H(n-1) - \\frac{2(n-1)}{n}\\) where \\(H(i)\\) is the harmonic number.\n",
        "\n",
        "For a dataset of 3000 data points:\n",
        "\\[ c(3000) \\approx 2 \\cdot (\\ln(3000) + \\gamma) - \\frac{2(3000-1)}{3000} \\]\n",
        "where \\(\\gamma \\approx 0.57721\\) (Euler-Mascheroni constant).\n",
        "\n",
        "Approximating \\( \\ln(3000) \\approx 8.006 \\):\n",
        "\\[ c(3000) \\approx 2 \\cdot (8.006 + 0.57721) - 1.999 \\approx 17.166 \\]\n",
        "\n",
        "Thus, the anomaly score:\n",
        "\\[ s(x, 3000) = 2^{-\\frac{5.0}{17.166}} \\approx 0.68 \\]\n",
        "\n",
        "This indicates the data point is moderately likely to be an anomaly."
      ],
      "metadata": {
        "id": "NabdPUXPiL8l"
      }
    }
  ]
}