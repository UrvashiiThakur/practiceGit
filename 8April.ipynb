{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOsafXwWb4KHg+p2h2v4zBo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/UrvashiiThakur/practiceGit/blob/main/8April.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FHL4V7agg6df"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q1. Best Regression Metric for Predicting House Prices\n",
        "\n",
        "For predicting house prices using an SVM regression model, the Mean Absolute Error (MAE) is often a suitable metric. MAE measures the average magnitude of errors in a set of predictions, without considering their direction. It is particularly useful in this context because:\n",
        "\n",
        "- **Interpretability**: MAE is easy to interpret, as it represents the average difference between the predicted and actual prices in the same unit (currency) as the target variable.\n",
        "- **Robustness to Outliers**: Unlike MSE (Mean Squared Error), MAE is less sensitive to outliers, making it a good choice when the dataset contains some outlier prices.\n",
        "\n",
        "### Q2. Choosing Between MSE and R-squared for House Price Prediction\n",
        "\n",
        "If your goal is to predict the actual price of a house as accurately as possible, Mean Squared Error (MSE) would be more appropriate. MSE provides a clear measure of the average squared difference between the predicted and actual values, penalizing larger errors more than smaller ones. This makes MSE useful when accuracy in prediction is crucial.\n",
        "\n",
        "### Q3. Regression Metric for a Dataset with Significant Outliers\n",
        "\n",
        "For a dataset with a significant number of outliers, the Mean Absolute Error (MAE) is the most appropriate metric. MAE is less sensitive to outliers compared to MSE, as it does not square the error term. This makes it more robust in scenarios where outliers could disproportionately influence the evaluation metric.\n",
        "\n",
        "### Q4. Choosing Between MSE and RMSE When Values Are Close\n",
        "\n",
        "When both MSE (Mean Squared Error) and RMSE (Root Mean Squared Error) values are very close, the choice between the two often comes down to interpretability:\n",
        "\n",
        "- **RMSE**: RMSE is the square root of MSE and is in the same unit as the target variable. It is more interpretable because it represents the average magnitude of the error.\n",
        "- **MSE**: MSE is the squared error and is more sensitive to larger errors.\n",
        "\n",
        "If both metrics are close, RMSE is generally preferred due to its interpretability in the same unit as the target variable.\n",
        "\n",
        "### Q5. Best Metric for Comparing SVM Models with Different Kernels\n",
        "\n",
        "When comparing the performance of different SVM regression models with different kernels (linear, polynomial, and RBF), the R-squared (\\( R^2 \\)) metric would be most appropriate if your goal is to measure how well the model explains the variance in the target variable. \\( R^2 \\) indicates the proportion of the variance in the dependent variable that is predictable from the independent variables. It is useful for:\n",
        "\n",
        "- **Comparative Analysis**: \\( R^2 \\) provides a clear comparison between models, showing which model explains the variance better.\n",
        "- **Model Explanation**: Higher \\( R^2 \\) values indicate better explanatory power of the model.\n",
        "\n",
        "### Example Workflow for SVM Regression Model\n",
        "\n",
        "1. **Import Libraries and Load Dataset**:\n",
        "   ```python\n",
        "   import pandas as pd\n",
        "   from sklearn.model_selection import train_test_split\n",
        "   from sklearn.preprocessing import StandardScaler\n",
        "   from sklearn.svm import SVR\n",
        "   from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "   # Load dataset\n",
        "   data = pd.read_csv('house_prices.csv')\n",
        "   ```\n",
        "\n",
        "2. **Split Dataset into Training and Testing Sets**:\n",
        "   ```python\n",
        "   X = data.drop('price', axis=1)\n",
        "   y = data['price']\n",
        "   X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "   ```\n",
        "\n",
        "3. **Preprocess the Data**:\n",
        "   ```python\n",
        "   scaler = StandardScaler()\n",
        "   X_train_scaled = scaler.fit_transform(X_train)\n",
        "   X_test_scaled = scaler.transform(X_test)\n",
        "   ```\n",
        "\n",
        "4. **Create and Train the SVR Model**:\n",
        "   ```python\n",
        "   svr = SVR(kernel='poly', degree=3, C=1.0, epsilon=0.1)\n",
        "   svr.fit(X_train_scaled, y_train)\n",
        "   ```\n",
        "\n",
        "5. **Predict and Evaluate the Model**:\n",
        "   ```python\n",
        "   y_pred = svr.predict(X_test_scaled)\n",
        "\n",
        "   # Calculate Metrics\n",
        "   mae = mean_absolute_error(y_test, y_pred)\n",
        "   mse = mean_squared_error(y_test, y_pred)\n",
        "   rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
        "   r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "   print(f\"MAE: {mae}\")\n",
        "   print(f\"MSE: {mse}\")\n",
        "   print(f\"RMSE: {rmse}\")\n",
        "   print(f\"R-squared: {r2}\")\n",
        "   ```\n",
        "\n",
        "6. **Tune Hyperparameters using GridSearchCV**:\n",
        "   ```python\n",
        "   from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "   param_grid = {\n",
        "       'C': [0.1, 1, 10, 100],\n",
        "       'kernel': ['linear', 'poly', 'rbf'],\n",
        "       'degree': [2, 3, 4],\n",
        "       'gamma': ['scale', 'auto'],\n",
        "       'epsilon': [0.1, 0.2, 0.3]\n",
        "   }\n",
        "\n",
        "   grid_search = GridSearchCV(SVR(), param_grid, refit=True, verbose=3)\n",
        "   grid_search.fit(X_train_scaled, y_train)\n",
        "   ```\n",
        "\n",
        "7. **Train the Tuned Model**:\n",
        "   ```python\n",
        "   best_svr = grid_search.best_estimator_\n",
        "   best_svr.fit(X_train_scaled, y_train)\n",
        "   ```\n",
        "\n",
        "8. **Save the Model**:\n",
        "   ```python\n",
        "   import pickle\n",
        "\n",
        "   with open('svr_model.pkl', 'wb') as file:\n",
        "       pickle.dump(best_svr, file)\n",
        "   ```"
      ],
      "metadata": {
        "id": "f5mYYsZ7g90a"
      }
    }
  ]
}